{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vn7mi5kP7VLn"
   },
   "source": [
    "### Problem Statement: \n",
    "#### Use Variational Autoencoder with Keras to generate images using the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OE6hiX3S7VLp"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu5l97z47VLw"
   },
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jET6Dct7VLx"
   },
   "outputs": [],
   "source": [
    "(input_train, target_train), (input_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEhFAwjL7VL2"
   },
   "source": [
    "### Data and model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jC6MoLeK7VL3"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = input_train.shape[1], input_train.shape[2]\n",
    "batch_size = 128\n",
    "no_epochs = 100\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "latent_dim = 2\n",
    "num_channels = 1\n",
    "\n",
    "# Reshape data\n",
    "input_train = input_train.reshape(input_train.shape[0], img_height, img_width, num_channels)\n",
    "input_test = input_test.reshape(input_test.shape[0], img_height, img_width, num_channels)\n",
    "input_shape = (img_height, img_width, num_channels)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9VtmTgr7VL8"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3z5SRaJ7VL9"
   },
   "outputs": [],
   "source": [
    "# Definition\n",
    "i       = Input(shape=input_shape, name='encoder_input')\n",
    "cx      = Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(i)\n",
    "cx      = BatchNormalization()(cx)\n",
    "cx      = Conv2D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(cx)\n",
    "cx      = BatchNormalization()(cx)\n",
    "x       = Flatten()(cx)\n",
    "x       = Dense(20, activation='relu')(x)\n",
    "x       = BatchNormalization()(x)\n",
    "mu      = Dense(latent_dim, name='latent_mu')(x)\n",
    "sigma   = Dense(latent_dim, name='latent_sigma')(x)\n",
    "\n",
    "# Get Conv2D shape for Conv2DTranspose operation in decoder\n",
    "conv_shape = K.int_shape(cx)\n",
    "\n",
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "  mu, sigma = args\n",
    "  batch     = K.shape(mu)[0]\n",
    "  dim       = K.int_shape(mu)[1]\n",
    "  eps       = K.random_normal(shape=(batch, dim))\n",
    "  return mu + K.exp(sigma / 2) * eps\n",
    "\n",
    "# Use reparameterization trick to ....??\n",
    "z       = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])\n",
    "\n",
    "# Instantiate encoder\n",
    "encoder = Model(i, [mu, sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8u0FV777VMB"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1BXpZBf7VMC"
   },
   "outputs": [],
   "source": [
    "# Definition\n",
    "d_i   = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "x     = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(d_i)\n",
    "x     = BatchNormalization()(x)\n",
    "x     = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "cx    = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "cx    = BatchNormalization()(cx)\n",
    "cx    = Conv2DTranspose(filters=8, kernel_size=3, strides=2, padding='same',  activation='relu')(cx)\n",
    "cx    = BatchNormalization()(cx)\n",
    "o     = Conv2DTranspose(filters=num_channels, kernel_size=3, activation='sigmoid', padding='same', name='decoder_output')(cx)\n",
    "\n",
    "# Instantiate decoder\n",
    "decoder = Model(d_i, o, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtIMMf-B7VMH"
   },
   "source": [
    "## VAE as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh6NtV0o7VMH"
   },
   "outputs": [],
   "source": [
    "# Instantiate VAE\n",
    "vae_outputs = decoder(encoder(i)[2])\n",
    "vae         = Model(i, vae_outputs, name='vae')\n",
    "vae.summary()\n",
    "\n",
    "# Define loss\n",
    "def kl_reconstruction_loss(true, pred):\n",
    "  # Reconstruction loss\n",
    "  reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height\n",
    "  # KL divergence loss\n",
    "  kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "  kl_loss = K.sum(kl_loss, axis=-1)\n",
    "  kl_loss *= -0.5\n",
    "  # Total loss = 50% rec + 50% KL divergence loss\n",
    "  return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "# Compile VAE\n",
    "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
    "\n",
    "# Train autoencoder\n",
    "vae.fit(input_train, input_train, epochs = no_epochs, batch_size = batch_size, validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCUQGnmx7VMO"
   },
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VA9dJrhl7VMP"
   },
   "outputs": [],
   "source": [
    "def viz_latent_space(encoder, data):\n",
    "  input_data, target_data = data\n",
    "  mu, _, _ = encoder.predict(input_data)\n",
    "  plt.figure(figsize=(8, 10))\n",
    "  plt.scatter(mu[:, 0], mu[:, 1], c=target_data)\n",
    "  plt.xlabel('z - dim 1')\n",
    "  plt.ylabel('z - dim 2')\n",
    "  plt.colorbar()\n",
    "  plt.show()\n",
    "\n",
    "def viz_decoded(encoder, decoder, data):\n",
    "  num_samples = 15\n",
    "  figure = np.zeros((img_width * num_samples, img_height * num_samples, num_channels))\n",
    "  grid_x = np.linspace(-4, 4, num_samples)\n",
    "  grid_y = np.linspace(-4, 4, num_samples)[::-1]\n",
    "  for i, yi in enumerate(grid_y):\n",
    "      for j, xi in enumerate(grid_x):\n",
    "          z_sample = np.array([[xi, yi]])\n",
    "          x_decoded = decoder.predict(z_sample)\n",
    "          digit = x_decoded[0].reshape(img_width, img_height, num_channels)\n",
    "          figure[i * img_width: (i + 1) * img_width,\n",
    "                  j * img_height: (j + 1) * img_height] = digit\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  start_range = img_width // 2\n",
    "  end_range = num_samples * img_width + start_range + 1\n",
    "  pixel_range = np.arange(start_range, end_range, img_width)\n",
    "  sample_range_x = np.round(grid_x, 1)\n",
    "  sample_range_y = np.round(grid_y, 1)\n",
    "  plt.xticks(pixel_range, sample_range_x)\n",
    "  plt.yticks(pixel_range, sample_range_y)\n",
    "  plt.xlabel('z - dim 1')\n",
    "  plt.ylabel('z - dim 2')\n",
    "  # matplotlib.pyplot.imshow() needs a 2D array, or a 3D array with the third dimension being of shape 3 or 4!\n",
    "  # So reshape if necessary\n",
    "  fig_shape = np.shape(figure)\n",
    "  if fig_shape[2] == 1:\n",
    "    figure = figure.reshape((fig_shape[0], fig_shape[1]))\n",
    "  # Show image\n",
    "  plt.imshow(figure)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLGeVnUz7VMT"
   },
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0tKQzlD7VMU"
   },
   "outputs": [],
   "source": [
    "data = (input_test, target_test)\n",
    "viz_latent_space(encoder, data)\n",
    "viz_decoded(encoder, decoder, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gaAM9Ai7VMY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.2_VAE with Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
